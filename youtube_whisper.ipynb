{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0mc4C_bbtRF"
      },
      "source": [
        "# YouTube Video Transcription with OpenAI's Whisper\n",
        "\n",
        "[![License](https://img.shields.io/github/license/kazuki-sf/youtube-whisper)](https://github.com/kazuki-sf/youtube-whisper)\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kazuki-sf/youtube-whisper/blob/main/youtube_whisper.ipynb)\n",
        "\n",
        "## How to Use the Notebook\n",
        "Feel free to `Copy to Drive` the notebook or run it directly.\n",
        "1. Enter the URL of the YouTube video or shorts you want to transcribe.\n",
        "2. Choose the whisper model you want to use.\n",
        "3. Run the code cell (Step 1-3) and wait for the transcription to complete.\n",
        "\n",
        "## Notes\n",
        "* `T4 GPU` or higher is recommended for running the notebook. You can change the runtime type by going to `Runtime` -> `Change runtime type` -> `Hardware accelerator` -> `GPU`.\n",
        "* Whenever you change the YouTube URL or Whisper Model, please run the `Step 1` and then run `Step 3` (You can skip `Step 2` if you already ran it before)\n",
        "* When you run `Step 3`, the website might ask you a permission to download multiple files.\n",
        "* This project is not affiliated with OpenAI. The code provided here is for educational purposes only.\n",
        "* Here's a list of whisper model and the relative speed of each model. For more information, please visit the official GitHub page: https://github.com/openai/whisper#available-models-and-languages\n",
        "---\n",
        "\n",
        "|  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "|:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "|  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
        "|  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
        "| small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
        "| medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
        "| large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "zT2cIQ_mbtRI"
      },
      "outputs": [],
      "source": [
        "# @title Step 1: Enter URL & Choose Whisper Model\n",
        "\n",
        "# @markdown Enter the URL of the YouTube video\n",
        "YouTube_URL = \"https://youtu.be/g2UCjJltqYs\" #@param {type:\"string\"}\n",
        "\n",
        "# @markdown Choose the whisper model you want to use\n",
        "whisper_model = \"large\" # @param [\"tiny\", \"base\", \"small\", \"medium\", \"large\", \"large-v2\", \"large-v3\"]\n",
        "\n",
        "# @markdown Save the transcription as text (.txt) file?\n",
        "text = True #@param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Save the transcription as an SRT (.srt) file?\n",
        "srt = False #@param {type:\"boolean\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "-LlBvCFVbtRJ",
        "outputId": "f8a9c2ef-b7a4-44d5-c760-da0b8d17e780",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Install Dependencies (this may take about 2-3 min)\n",
        "\n",
        "!pip install -q pytube\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "\n",
        "import os, re\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from pytube import YouTube\n",
        "import whisper\n",
        "from whisper.utils import get_writer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "collapsed": true,
        "id": "M-G2uj2sbtRK",
        "outputId": "d2b66e44-c19b-4414-8e4c-4eeed4a5bc59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.88G/2.88G [00:32<00:00, 93.6MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==> Downloading audio...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PytubeError",
          "evalue": "Exception while accessing title of https://youtube.com/watch?v=g2UCjJltqYs. Please file a bug report at https://github.com/pytube/pytube",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/__main__.py\u001b[0m in \u001b[0;36mtitle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvid_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'videoDetails'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'videoDetails'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mPytubeError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a3d8a6b3efa8>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Download & Transcribe the audio data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_audio_from_youtube\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYouTube_URL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscribe_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-a3d8a6b3efa8>\u001b[0m in \u001b[0;36mdownload_audio_from_youtube\u001b[0;34m(url, file_name, out_dir)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYouTube\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_snake_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     yt = (yt.streams\n\u001b[1;32m     17\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_extension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/__main__.py\u001b[0m in \u001b[0;36mtitle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m#  if it doesn't, ask for a report.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_availability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             raise exceptions.PytubeError(\n\u001b[0m\u001b[1;32m    347\u001b[0m                 (\n\u001b[1;32m    348\u001b[0m                     \u001b[0;34mf'Exception while accessing title of {self.watch_url}. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPytubeError\u001b[0m: Exception while accessing title of https://youtube.com/watch?v=g2UCjJltqYs. Please file a bug report at https://github.com/pytube/pytube"
          ]
        }
      ],
      "source": [
        "# Step 3: Transcribe the video/audio data\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = whisper.load_model(whisper_model).to(device)\n",
        "\n",
        "# Util function to change name\n",
        "def to_snake_case(name):\n",
        "    return name.lower().replace(\" \", \"_\").replace(\":\", \"_\").replace(\"__\", \"_\")\n",
        "\n",
        "# Download the audio data from YouTube video\n",
        "def download_audio_from_youtube(url,  file_name = None, out_dir = \".\"):\n",
        "    print(f\"\\n==> Downloading audio...\")\n",
        "    yt = YouTube(url)\n",
        "    if file_name is None:\n",
        "        file_name = Path(out_dir, to_snake_case(yt.title)).with_suffix(\".mp4\")\n",
        "    yt = (yt.streams\n",
        "            .filter(only_audio = True, file_extension = \"mp4\")\n",
        "            .order_by(\"abr\")\n",
        "            .desc())\n",
        "    return yt.first().download(filename = file_name)\n",
        "\n",
        "\n",
        "# Transcribe the audio data with Whisper\n",
        "def transcribe_audio(model, file, text, srt):\n",
        "    print(\"\\n=======================\")\n",
        "    print(f\"\\nğŸ”— YouTube URL: {YouTube_URL}\")\n",
        "    print(f\"\\nğŸ¤– Whisper Model: {whisper_model}\")\n",
        "    print(\"\\n=======================\")\n",
        "\n",
        "    file_path = Path(file)\n",
        "    output_directory = file_path.parent\n",
        "\n",
        "    # Run Whisper to transcribe audio\n",
        "    print(f\"\\n==> Transcribing audio\")\n",
        "    result = model.transcribe(file, verbose = False)\n",
        "\n",
        "    if text:\n",
        "        print(f\"\\n==> Creating .txt file\")\n",
        "        txt_path = file_path.with_suffix(\".txt\")\n",
        "        with open(txt_path, \"w\", encoding=\"utf-8\") as txt:\n",
        "            txt.write(result[\"text\"])\n",
        "    if srt:\n",
        "        print(f\"\\n==> Creating .srt file\")\n",
        "        srt_writer = get_writer(\"srt\", output_directory)\n",
        "        srt_writer(result, str(file_path.stem))\n",
        "\n",
        "    # Download the transcribed files locally\n",
        "    from google.colab import files\n",
        "\n",
        "    colab_files = Path(\"/content\")\n",
        "    stem = file_path.stem\n",
        "\n",
        "    for colab_file in colab_files.glob(f\"{stem}*\"):\n",
        "        if colab_file.suffix in [\".txt\", \".srt\"]:\n",
        "            files.download(str(colab_file))\n",
        "\n",
        "    print(\"\\nâœ¨ All Done!\")\n",
        "    print(\"=======================\")\n",
        "    return result\n",
        "\n",
        "# Download & Transcribe the audio data\n",
        "audio = download_audio_from_youtube(YouTube_URL)\n",
        "result = transcribe_audio(model, audio, text, srt)"
      ]
    },
    {
      "source": [
        "!pip install -U pytube"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "dz0izfnadHGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Step 2: Install Dependencies (this may take about 2-3 min)\n",
        "!pip install -q pytube\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -U pytube # This was added to install the latest version of pytube\n",
        "\n",
        "import os, re\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from pytube import YouTube\n",
        "import whisper\n",
        "from whisper.utils import get_writer\n",
        "\n",
        "# Util function to change name\n",
        "def to_snake_case(name):\n",
        "    return name.lower().replace(\" \", \"_\").replace(\":\", \"_\").replace(\"__\", \"_\")\n",
        "\n",
        "# Download the audio data from YouTube video\n",
        "def download_audio_from_youtube(url,  file_name = None, out_dir = \".\"):\n",
        "    print(f\"\\n==> Downloading audio...\")\n",
        "    yt = YouTube(url)\n",
        "\n",
        "    if file_name is None:\n",
        "        # Try to get the title using the old method\n",
        "        try:\n",
        "            file_name = Path(out_dir, to_snake_case(yt.title)).with_suffix(\".mp4\")\n",
        "        # If that fails, use the 'watch_html' and regex to get the title.\n",
        "        except KeyError:\n",
        "            title_match = re.search('<title>(.*?) - YouTube</title>', yt.watch_html)\n",
        "            if title_match:\n",
        "                file_name = Path(out_dir, to_snake_case(title_match.group(1))).with_suffix(\".mp4\")\n",
        "            else:\n",
        "                raise Exception(\"Could not extract the title from the YouTube video.\")\n",
        "\n",
        "\n",
        "    yt = (yt.streams\n",
        "            .filter(only_audio = True, file_extension = \"mp4\")\n",
        "            .order_by(\"abr\")\n",
        "            .desc())\n",
        "    return yt.first().download(filename = file_name)\n",
        "\n",
        "\n",
        "# Transcribe the audio data with Whisper\n",
        "def transcribe_audio(model, file, text, srt):\n",
        "    print(\"\\n=======================\")\n",
        "    print(f\"\\nğŸ”— YouTube URL: {YouTube_URL}\")\n",
        "    print(f\"\\nğŸ¤– Whisper Model: {whisper_model}\")\n",
        "    print(\"\\n=======================\")\n",
        "\n",
        "    file_path = Path(file)\n",
        "    output_directory = file_path.parent\n",
        "\n",
        "    # Run Whisper to transcribe audio\n",
        "    print(f\"\\n==> Transcribing audio\")\n",
        "    result = model.transcribe(file, verbose = False)\n",
        "\n",
        "    if text:\n",
        "        print(f\"\\n==> Creating .txt file\")\n",
        "        txt_path = file_path.with_suffix(\".txt\")\n",
        "        with open(txt_path, \"w\", encoding=\"utf-8\") as txt:\n",
        "            txt.write(result[\"text\"])\n",
        "    if srt:\n",
        "        print(f\"\\n==> Creating .srt file\")\n",
        "        srt_writer = get_writer(\"srt\", output_directory)\n",
        "        srt_writer(result, str(file_path.stem))\n",
        "\n",
        "    # Download the transcribed files locally\n",
        "    from google.colab import files\n",
        "\n",
        "    colab_files = Path(\"/content\")\n",
        "    stem = file_path.stem\n",
        "\n",
        "    for colab_file in colab_files.glob(f\"{stem}*\"):\n",
        "        if colab_file.suffix in [\".txt\", \".srt\"]:\n",
        "            files.download(str(colab_file))\n",
        "\n",
        "    print(\"\\nâœ¨ All Done!\")\n",
        "    print(\"=======================\")\n",
        "    return result\n",
        "\n",
        "# Download & Transcribe the audio data\n",
        "audio = download_audio_from_youtube(YouTube"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Uz_U0G4jdOoD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}